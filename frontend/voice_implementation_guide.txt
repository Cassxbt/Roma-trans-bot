# ðŸŽ™ï¸ Voice Translation Setup Guide

**Roma Translation Bot - Voice Integration**  
Add speech-to-text + translation for Discord & Telegram voice messages

---

## ðŸ“‹ Table of Contents

1. [Prerequisites](#prerequisites)
2. [Quick Start (15 minutes)](#quick-start)
3. [Detailed Setup](#detailed-setup)
4. [Discord Integration](#discord-integration)
5. [Telegram Integration](#telegram-integration)
6. [Testing](#testing)
7. [Troubleshooting](#troubleshooting)
8. [API Reference](#api-reference)

---

## Prerequisites

Before starting, ensure you have:

- âœ… Roma-trans-bot repository cloned and working
- âœ… Discord and/or Telegram bot already functional with text translation
- âœ… Python 3.12+ installed
- âœ… Virtual environment activated (`venv312`)
- âœ… `.env` file configured with existing API keys

**New Requirements:**
- Hugging Face account (free): https://huggingface.co/join
- Internet connection (all processing is cloud-based)

---

## Quick Start

### Step 1: Get Hugging Face Token (2 minutes)

1. Go to: https://huggingface.co/settings/tokens
2. Click **"New token"**
3. Settings:
   - **Name:** `roma-voice-bot`
   - **Role:** `Read`
4. Click **"Generate token"**
5. Copy the token (starts with `hf_...`)

### Step 2: Add Token to .env (1 minute)

Open your `.env` file and add:

```bash
# Hugging Face Configuration (for voice transcription)
HF_TOKEN=hf_your_actual_token_here
```

**Important:** Replace `hf_your_actual_token_here` with your actual token.

### Step 3: Install Dependencies (2 minutes)

```bash
cd Roma-trans-bot
source venv312/bin/activate

# Install required packages
pip install requests python-dotenv

# Update requirements.txt
echo "requests>=2.31.0" >> requirements.txt
echo "python-dotenv>=1.0.0" >> requirements.txt
```

### Step 4: Create Whisper Service (3 minutes)

Create the file: `src/services/hf_whisper_service.py`

```bash
mkdir -p src/services
touch src/services/hf_whisper_service.py
```

Copy this code into `src/services/hf_whisper_service.py`:

```python
"""
Cloud-based ASR using Whisper via Hugging Face Inference API
Zero downloads, 100% cloud processing
"""
import requests
import os
import hashlib
import json
import time
from typing import Dict, Optional
from datetime import datetime, timedelta

class HFWhisperASR:
    """Production-ready Whisper ASR service"""
    
    def __init__(self, hf_token: Optional[str] = None, enable_cache: bool = True):
        """Initialize HF Whisper ASR service"""
        self.api_url = "https://api-inference.huggingface.co/models/openai/whisper-large-v3"
        self.headers = {}
        
        token = hf_token or os.getenv("HF_TOKEN")
        if token:
            self.headers["Authorization"] = f"Bearer {token}"
            print("âœ… HF Whisper ASR initialized with token")
        else:
            print("âš ï¸  No HF token found. Rate limits will be restricted.")
        
        self.enable_cache = enable_cache
        self.cache = {}
        self.cache_file = "asr_cache.json"
        
        if enable_cache:
            self._load_cache()
    
    def _load_cache(self):
        """Load cache from disk"""
        try:
            if os.path.exists(self.cache_file):
                with open(self.cache_file, 'r') as f:
                    self.cache = json.load(f)
                print(f"ðŸ“¦ Loaded {len(self.cache)} cached transcriptions")
        except Exception as e:
            print(f"âš ï¸  Could not load cache: {e}")
    
    def _save_cache(self):
        """Save cache to disk"""
        try:
            with open(self.cache_file, 'w') as f:
                json.dump(self.cache, f)
        except Exception as e:
            print(f"âš ï¸  Could not save cache: {e}")
    
    def _get_audio_hash(self, audio_path: str) -> str:
        """Generate unique hash for audio file"""
        with open(audio_path, 'rb') as f:
            return hashlib.md5(f.read()).hexdigest()
    
    def transcribe_audio(self, audio_path: str) -> Dict:
        """Transcribe audio file using HF Inference API"""
        
        # Check cache first
        if self.enable_cache:
            audio_hash = self._get_audio_hash(audio_path)
            if audio_hash in self.cache:
                print("âœ… Using cached transcription")
                result = self.cache[audio_hash].copy()
                result["cached"] = True
                return result
        
        try:
            with open(audio_path, "rb") as f:
                audio_bytes = f.read()
            
            print(f"ðŸ”Š Transcribing audio ({len(audio_bytes)} bytes)...")
            response = requests.post(
                self.api_url,
                headers=self.headers,
                data=audio_bytes,
                timeout=60
            )
            
            if response.status_code == 200:
                result_data = response.json()
                
                result = {
                    "text": result_data.get("text", "").strip(),
                    "success": True,
                    "model": "whisper-large-v3",
                    "cached": False,
                    "timestamp": datetime.now().isoformat()
                }
                
                # Cache successful transcription
                if self.enable_cache:
                    audio_hash = self._get_audio_hash(audio_path)
                    self.cache[audio_hash] = result
                    self._save_cache()
                
                return result
            
            elif response.status_code == 503:
                return {
                    "text": "",
                    "success": False,
                    "error": "Model loading (cold start). Retry in 30s.",
                    "retry": True,
                    "cached": False
                }
            
            elif response.status_code == 429:
                return {
                    "text": "",
                    "success": False,
                    "error": "Rate limit exceeded. Try again in 1 hour.",
                    "retry": False,
                    "cached": False
                }
            
            else:
                return {
                    "text": "",
                    "success": False,
                    "error": f"API error {response.status_code}",
                    "retry": False,
                    "cached": False
                }
        
        except Exception as e:
            return {
                "text": "",
                "success": False,
                "error": str(e),
                "retry": False,
                "cached": False
            }
    
    def transcribe_with_retry(self, audio_path: str, max_retries: int = 3) -> Dict:
        """Transcribe with automatic retry for cold starts"""
        for attempt in range(max_retries):
            result = self.transcribe_audio(audio_path)
            
            if result["success"]:
                print(f"âœ… Transcription: '{result['text'][:50]}...'")
                return result
            
            if result.get("retry") and attempt < max_retries - 1:
                wait_time = 30 * (attempt + 1)
                print(f"â³ Retry {attempt + 1}/{max_retries}: waiting {wait_time}s...")
                time.sleep(wait_time)
                continue
            
            return result
        
        return {"text": "", "success": False, "error": "Max retries exceeded"}
```

### Step 5: Test the Service (2 minutes)

```bash
python -c "from src.services.hf_whisper_service import HFWhisperASR; print('âœ… Service ready!')"
```

If you see `âœ… Service ready!`, you're good to go!

---

## Detailed Setup

### Understanding How It Works

```
User sends voice note
        â†“
Bot downloads voice file (temporary)
        â†“
Sends to Hugging Face Whisper API (cloud)
        â†“
Gets transcribed text back
        â†“
Passes text to ROMA translation agent
        â†“
Returns translations in selected languages
        â†“
Deletes temporary file
```

**Key Points:**
- âœ… No models downloaded to your computer (0MB disk space)
- âœ… No GPU needed (all processing in cloud)
- âœ… First transcription takes 30-60s (cold start)
- âœ… Subsequent transcriptions are instant (if cached)
- âœ… Works on any device (even MacBook Air)

---

## Discord Integration

### Step 1: Modify Discord Bot

Open `src/bots/discord_bot.py`

**Add imports at the top:**

```python
from src.services.hf_whisper_service import HFWhisperASR
import tempfile
import os
```

**Add to your bot's `__init__` method:**

```python
class TranslationBot(commands.Bot):
    def __init__(self):
        super().__init__(command_prefix='!', intents=discord.Intents.all())
        self.translation_agent = TranslationAgent()
        
        # Add this line:
        self.asr = HFWhisperASR(enable_cache=True)
```

### Step 2: Add Voice Translation Command

Add this method to your `TranslationBot` class:

```python
@commands.command(name='voicetrans', aliases=['vt'])
async def voice_translate(self, ctx, *languages):
    """
    ðŸŽ™ï¸ Transcribe voice message and translate
    Usage: !voicetrans chinese french korean (attach audio)
    """
    # Check for audio attachment
    if not ctx.message.attachments:
        await ctx.send("âŒ Please attach an audio file!")
        return
    
    attachment = ctx.message.attachments[0]
    
    # Validate file format
    valid_formats = ('.wav', '.mp3', '.m4a', '.flac', '.ogg', '.opus')
    if not attachment.filename.lower().endswith(valid_formats):
        await ctx.send(f"âŒ Invalid format. Use: WAV, MP3, M4A, FLAC, OGG")
        return
    
    # Default languages if none specified
    if not languages:
        languages = ["chinese", "french", "korean"]
    
    # Processing message
    processing_msg = await ctx.send("ðŸŽ™ï¸ Transcribing your voice message...")
    
    # Download audio to temporary file
    with tempfile.NamedTemporaryFile(
        suffix=f".{attachment.filename.split('.')[-1]}", 
        delete=False
    ) as tmp_file:
        await attachment.save(tmp_file.name)
        audio_path = tmp_file.name
    
    try:
        # Step 1: Transcribe with Whisper
        asr_result = self.asr.transcribe_with_retry(audio_path)
        
        if not asr_result["success"]:
            await processing_msg.edit(
                content=f"âŒ Transcription failed: {asr_result.get('error', 'Unknown error')}"
            )
            return
        
        transcribed_text = asr_result["text"]
        
        # Update status
        await processing_msg.edit(
            content=f"ðŸ“ **Said:** {transcribed_text}\n\nðŸ”„ Translating..."
        )
        
        # Step 2: Translate using ROMA
        translation_result = await self.translation_agent.translate(
            text=transcribed_text,
            target_languages=list(languages)
        )
        
        # Step 3: Format response
        response_embed = discord.Embed(
            title="ðŸŽ™ï¸ Voice Translation",
            description=f"**Original:** {transcribed_text}",
            color=discord.Color.green()
        )
        
        # Add translations
        flags = {
            "chinese": "ðŸ‡¨ðŸ‡³", "english": "ðŸ‡¬ðŸ‡§", "french": "ðŸ‡«ðŸ‡·",
            "turkish": "ðŸ‡¹ðŸ‡·", "korean": "ðŸ‡°ðŸ‡·"
        }
        
        for lang in languages:
            flag = flags.get(lang.lower(), "ðŸŒ")
            translation = translation_result.get(lang, "Translation unavailable")
            response_embed.add_field(
                name=f"{flag} {lang.capitalize()}",
                value=translation,
                inline=False
            )
        
        response_embed.set_footer(
            text=f"Cached: {'Yes' if asr_result.get('cached') else 'No'}"
        )
        
        await processing_msg.edit(content="", embed=response_embed)
    
    except Exception as e:
        await processing_msg.edit(content=f"âŒ Error: {str(e)}")
    
    finally:
        # Clean up temporary file
        if os.path.exists(audio_path):
            os.unlink(audio_path)
```

### Step 3: Add Voice Help Command

```python
@commands.command(name='voicehelp')
async def voice_help(self, ctx):
    """Show voice translation help"""
    embed = discord.Embed(
        title="ðŸŽ™ï¸ Voice Translation Commands",
        description="Send voice messages for instant translation",
        color=discord.Color.purple()
    )
    
    embed.add_field(
        name="ðŸ“± How to Use",
        value=(
            "1. Record a voice message or upload audio file\n"
            "2. Use: `!voicetrans chinese french korean`\n"
            "3. Bot transcribes and translates automatically"
        ),
        inline=False
    )
    
    embed.add_field(
        name="ðŸŒ Supported Languages",
        value="ðŸ‡¨ðŸ‡³ Chinese | ðŸ‡¬ðŸ‡§ English | ðŸ‡«ðŸ‡· French | ðŸ‡¹ðŸ‡· Turkish | ðŸ‡°ðŸ‡· Korean",
        inline=False
    )
    
    embed.add_field(
        name="ðŸŽµ Supported Formats",
        value="WAV, MP3, M4A, FLAC, OGG, OPUS",
        inline=False
    )
    
    embed.add_field(
        name="ðŸ’¡ Tips",
        value=(
            "â€¢ Keep audio under 30 seconds\n"
            "â€¢ Speak clearly for best results\n"
            "â€¢ First use takes 30-60s (then instant)\n"
            "â€¢ Default: Chinese, French, Korean"
        ),
        inline=False
    )
    
    await ctx.send(embed=embed)
```

### Step 4: Test Discord Bot

```bash
python run_discord_bot.py
```

**In Discord:**
1. Upload an audio file
2. Type: `!voicetrans chinese french`
3. Watch it transcribe and translate!

---

## Telegram Integration

### Step 1: Modify Telegram Bot

Open `src/bots/telegram_bot.py`

**Add imports at the top:**

```python
from telegram import Update
from telegram.ext import MessageHandler, filters
from src.services.hf_whisper_service import HFWhisperASR
import tempfile
import os
```

**Initialize ASR service:**

```python
# After your other initializations
asr = HFWhisperASR(enable_cache=True)
translation_agent = TranslationAgent()
```

### Step 2: Add Voice Message Handler

Add this function:

```python
async def handle_voice_message(update: Update, context):
    """
    Automatically handle voice messages
    Users can optionally specify languages: /voicetrans chinese french
    """
    await update.message.reply_text("ðŸŽ™ï¸ Transcribing your voice message...")
    
    # Get voice file
    voice = await update.message.voice.get_file()
    
    # Download to temporary file
    with tempfile.NamedTemporaryFile(delete=False, suffix='.ogg') as tmp:
        await voice.download_to_drive(tmp.name)
        audio_path = tmp.name
    
    try:
        # Step 1: Transcribe
        result = asr.transcribe_with_retry(audio_path)
        
        if not result['success']:
            await update.message.reply_text(
                f"âŒ Transcription failed: {result.get('error', 'Unknown error')}"
            )
            return
        
        transcribed_text = result['text']
        
        # Step 2: Get target languages (default if not specified)
        target_langs = context.args if context.args else ['Chinese', 'French', 'Korean']
        
        # Update user
        await update.message.reply_text(
            f"ðŸ“ *You said:* {transcribed_text}\n\nðŸ”„ Translating...",
            parse_mode='Markdown'
        )
        
        # Step 3: Translate
        translations = translation_agent.translate(
            text=transcribed_text,
            target_languages=target_langs
        )
        
        # Step 4: Format response
        response = f"ðŸ“ *Original:*\n{transcribed_text}\n\n*Translations:*\n"
        
        flags = {
            "chinese": "ðŸ‡¨ðŸ‡³", "english": "ðŸ‡¬ðŸ‡§", "french": "ðŸ‡«ðŸ‡·",
            "turkish": "ðŸ‡¹ðŸ‡·", "korean": "ðŸ‡°ðŸ‡·"
        }
        
        for lang, translation in translations.items():
            flag = flags.get(lang.lower(), "ðŸŒ")
            response += f"{flag} *{lang}:* {translation}\n"
        
        response += f"\nðŸ’¾ Cached: {'Yes' if result.get('cached') else 'No'}"
        
        await update.message.reply_text(response, parse_mode='Markdown')
    
    except Exception as e:
        await update.message.reply_text(f"âŒ Error: {str(e)}")
    
    finally:
        # Clean up
        if os.path.exists(audio_path):
            os.unlink(audio_path)


async def voicetrans_command(update: Update, context):
    """
    Set target languages for next voice message
    Usage: /voicetrans chinese french korean
    """
    if not context.args:
        await update.message.reply_text(
            "ðŸŽ™ï¸ *Voice Translation*\n\n"
            "Usage: `/voicetrans chinese french korean`\n"
            "Then send a voice message!\n\n"
            "Supported: ðŸ‡¨ðŸ‡³ Chinese | ðŸ‡¬ðŸ‡§ English | ðŸ‡«ðŸ‡· French | ðŸ‡¹ðŸ‡· Turkish | ðŸ‡°ðŸ‡· Korean",
            parse_mode='Markdown'
        )
    else:
        await update.message.reply_text(
            f"âœ… Target languages set: {', '.join(context.args)}\n"
            "Now send me a voice message!",
            parse_mode='Markdown'
        )
```

### Step 3: Register Handlers

In your main application setup:

```python
# Add voice message handler
app.add_handler(MessageHandler(filters.VOICE, handle_voice_message))

# Add voicetrans command
app.add_handler(CommandHandler("voicetrans", voicetrans_command))
```

### Step 4: Test Telegram Bot

```bash
python run_telegram_bot.py
```

**In Telegram:**
1. Open your bot
2. **Hold the microphone button** and record a message
3. Release to send
4. Bot automatically transcribes and translates!

---

## Testing

### Test 1: Verify Setup

```bash
python -c "
from src.services.hf_whisper_service import HFWhisperASR
import os
from dotenv import load_dotenv

load_dotenv()

print('Testing setup...')
print(f'HF_TOKEN exists: {bool(os.getenv(\"HF_TOKEN\"))}')

asr = HFWhisperASR()
print('âœ… All systems ready!')
"
```

### Test 2: Discord Voice Translation

1. **In Discord:**
   - Type `!voicehelp` to see commands
   - Upload a short audio file (or record on phone and upload)
   - Type: `!voicetrans chinese french`
   - Wait for transcription and translation

2. **Expected Result:**
   ```
   ðŸŽ™ï¸ Voice Translation
   Original: Hello, this is a test message

   ðŸ‡¨ðŸ‡³ Chinese: ä½ å¥½ï¼Œè¿™æ˜¯ä¸€æ¡æµ‹è¯•æ¶ˆæ¯
   ðŸ‡«ðŸ‡· French: Bonjour, ceci est un message de test

   Cached: No
   ```

### Test 3: Telegram Voice Note

1. **In Telegram:**
   - Open your bot
   - **Hold microphone button** in message box
   - Speak: "Hello, translate this to French"
   - Release button (sends voice note)
   - Bot processes automatically

2. **Expected Result:**
   ```
   ðŸ“ You said: Hello, translate this to French

   Translations:
   ðŸ‡¨ðŸ‡³ Chinese: ä½ å¥½ï¼ŒæŠŠè¿™ä¸ªç¿»è¯‘æˆæ³•è¯­
   ðŸ‡«ðŸ‡· French: Bonjour, traduisez ceci en franÃ§ais
   ðŸ‡°ðŸ‡· Korean: ì•ˆë…•í•˜ì„¸ìš”, ì´ê²ƒì„ í”„ëž‘ìŠ¤ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”

   ðŸ’¾ Cached: No
   ```

### Test 4: Caching

1. Send the same voice message again
2. Should get instant response
3. Look for `Cached: Yes`

---

## Troubleshooting

### Issue: "HF_TOKEN not found"

**Solution:**
1. Check your `.env` file has: `HF_TOKEN=hf_...`
2. Make sure token starts with `hf_`
3. No spaces around the `=` sign
4. Restart your bot after adding token

### Issue: "Model loading" or 503 error

**Solution:**
- This is normal for first request (cold start)
- Wait 30-60 seconds and try again
- The bot will automatically retry 3 times

### Issue: "Rate limit exceeded" (429 error)

**Solution:**
- Free tier: ~200-300 requests/hour with token
- Wait 1 hour for reset
- Or upgrade to HF Pro ($9/month) for unlimited

### Issue: Audio file not recognized

**Solution:**
- Supported formats: WAV, MP3, M4A, FLAC, OGG, OPUS
- Discord: Upload directly from your device
- Telegram: Use the microphone button (not file attachment)

### Issue: "Translation unavailable"

**Solution:**
- Check your ROMA translation agent is configured
- Verify DeepL/Azure API keys in `.env`
- Check language names match exactly: "chinese", "french", etc.

### Issue: Discord bot not responding to voice

**Solution:**
1. Make sure you uploaded an audio file
2. Check you typed the command: `!voicetrans chinese french`
3. Verify bot has permission to read attachments
4. Check bot logs for errors

### Issue: Telegram not receiving voice notes

**Solution:**
1. Use the **microphone button** in Telegram (bottom right)
2. Don't send audio files as documents
3. Hold button â†’ speak â†’ release (this creates voice note)
4. Check bot has access to voice messages in BotFather settings

---

## API Reference

### HFWhisperASR Methods

#### `__init__(hf_token=None, enable_cache=True)`
Initialize the ASR service
- `hf_token`: Optional HF token (reads from env if not provided)
- `enable_cache`: Enable caching to reduce API calls

#### `transcribe_audio(audio_path: str) -> Dict`
Transcribe audio file once
- Returns: `{"text": str, "success": bool, "error": str, "cached": bool}`

#### `transcribe_with_retry(audio_path: str, max_retries=3) -> Dict`
Transcribe with automatic retry for cold starts
- Recommended for production use
- Handles 503 errors automatically

### Response Format

```python
{
    "text": "Transcribed text here",
    "success": True,
    "model": "whisper-large-v3",
    "cached": False,
    "timestamp": "2024-01-15T10:30:00"
}
```

### Error Codes

| Code | Meaning | Action |
|------|---------|--------|
| 200 | Success | Use the result |
| 503 | Model loading | Retry after 30s (automatic) |
| 429 | Rate limit | Wait 1 hour |
| 400 | Bad request | Check audio format |
| 401 | Invalid token | Check HF_TOKEN in .env |

---

## Performance & Limits

### Free Tier (with token)
- **Requests:** ~200-300 per hour
- **Audio length:** Up to 30 seconds recommended
- **File size:** Max 10MB
- **Languages:** 99 languages supported
- **Cost:** $0 forever

### Response Times
- **First request:** 30-60 seconds (cold start)
- **Cached:** Instant (<100ms)
- **Regular:** 2-5 seconds

### Best Practices
1. âœ… Keep audio under 30 seconds
2. âœ… Enable caching (enabled by default)
3. âœ… Use voice notes (not file uploads) in Telegram
4. âœ… Clear speech, minimal background noise
5. âœ… Test with short clips first

---

## Support

### Need Help?

1. **Check logs:** Run your bot and watch console output
2. **Test service:** `python src/services/hf_whisper_service.py`
3. **Verify token:** Check https://huggingface.co/settings/tokens
4. **Check status:** https://status.huggingface.co

### Useful Commands

```bash
# Test ASR service
python -c "from src.services.hf_whisper_service import HFWhisperASR; asr = HFWhisperASR(); print(asr.get_cache_stats())"

# Clear cache
python -c "from src.services.hf_whisper_service import HFWhisperASR; asr = HFWhisperASR(); asr.clear_cache()"

# Check environment
python -c "import os; from dotenv import load_dotenv; load_dotenv(); print('HF_TOKEN:', 'Set' if os.getenv('HF_TOKEN') else 'Missing')"
```

---

## What's Next?

Once voice translation is working:

1. **Add more languages:** Whisper supports 99 languages
2. **Add web frontend:** Create a React UI for voice upload
3. **Add audio file support:** Let users upload longer audio files
4. **Add language detection:** Auto-detect source language
5. **Add pronunciation:** Text-to-speech for translations

---

## Summary Checklist

- [ ] HF token obtained and added to `.env`
- [ ] Dependencies installed (`requests`, `python-dotenv`)
- [ ] `hf_whisper_service.py` created in `src/services/`
- [ ] Discord bot modified with voice commands
- [ ] Telegram bot modified with voice handler
- [ ] Tested with short voice message
- [ ] Verified caching works
- [ ] Documented for team

---

**ðŸŽ‰ Congratulations!** Your Roma bot now supports voice translation!

Users can:
- ðŸŽ™ï¸ Send voice notes in Discord/Telegram
- ðŸŒ Get instant translations in 5 languages
- âš¡ Enjoy cached results for repeated messages
- ðŸ’» Use any device (zero local resources)

For questions or issues, check the Troubleshooting section above.
